{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem : Bike Renting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataSet\n",
    "os.chdir(\"/Users/bhartisharma/Desktop/Bike Renting\")\n",
    "dataset = pd.read_csv(\"Day.csv\")\n",
    "dataset_copy = dataset.copy()\n",
    "dataset_copy1=dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions of Data\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Information\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of Data\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataCat is a dataframe containing all categorical variables from dataset\n",
    "DataCat = pd.DataFrame()\n",
    "DataCat = dataset[['instant','dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit']]\n",
    "\n",
    "#DataCon is a dataframe containing all continuous variables from dataset\n",
    "DataCon = pd.DataFrame()\n",
    "DataCon = dataset[['temp', 'atemp', 'hum', 'windspeed','casual', 'registered', 'cnt']]\n",
    "\n",
    "#Continuous data is already in float and int type , But we have to convert categorical variables to object type\n",
    "#Converting some integer and float variables to categorical variable as per requirement\n",
    "dataset[DataCat.columns] = dataset[DataCat.columns].astype(object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weathersit \n",
    "#weathersit: As per problem statement\n",
    "#1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "#2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "#3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "#4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\n",
    "\n",
    "r,c =dataset.shape\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('weathersit')] == 1):\n",
    "        dataset.loc[i,('weathersit')] = ' Partly cloudy'\n",
    "    elif(dataset.loc[i,('weathersit')] == 2):\n",
    "        dataset.loc[i,('weathersit')] = 'cloudy'\n",
    "    elif(dataset.loc[i,('weathersit')] == 3):\n",
    "        dataset.loc[i,('weathersit')] = 'Light Rain'\n",
    "    elif(dataset.loc[i,('weathersit')] == 4):\n",
    "        dataset.loc[i,('weathersit')] = 'Heavy Rain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year (0: 2011, 1:2012)\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('yr')] == 0):\n",
    "        dataset.loc[i,('yr')] = '2011'\n",
    "    elif(dataset.loc[i,('yr')] == 1):\n",
    "        dataset.loc[i,('yr')] = '2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seasons (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('season')] == 1):\n",
    "        dataset.loc[i,('season')] = 'springer'\n",
    "    elif(dataset.loc[i,('season')] == 2):\n",
    "        dataset.loc[i,('season')] = 'summer'\n",
    "    elif(dataset.loc[i,('season')] == 3):\n",
    "        dataset.loc[i,('season')] = 'fall'\n",
    "    elif(dataset.loc[i,('season')] == 4):\n",
    "        dataset.loc[i,('season')] = 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnth: Month (1 to 12)\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('mnth')] == 1):\n",
    "        dataset.loc[i,('mnth')] = 'January'\n",
    "    elif(dataset.loc[i,('mnth')] == 2):\n",
    "        dataset.loc[i,('mnth')] = 'February'\n",
    "    elif(dataset.loc[i,('mnth')] == 3):\n",
    "        dataset.loc[i,('mnth')] = 'March'\n",
    "    elif(dataset.loc[i,('mnth')] == 4):\n",
    "        dataset.loc[i,('mnth')] = 'April'\n",
    "    elif(dataset.loc[i,('mnth')] == 5):\n",
    "        dataset.loc[i,('mnth')] = 'May'\n",
    "    elif(dataset.loc[i,('mnth')] == 6):\n",
    "        dataset.loc[i,('mnth')] = 'June'\n",
    "    elif(dataset.loc[i,('mnth')] == 7):\n",
    "        dataset.loc[i,('mnth')] = 'July'\n",
    "    elif(dataset.loc[i,('mnth')] == 8):\n",
    "        dataset.loc[i,('mnth')] = 'August'\n",
    "    elif(dataset.loc[i,('mnth')] == 9):\n",
    "        dataset.loc[i,('mnth')] = 'September'\n",
    "    elif(dataset.loc[i,('mnth')] == 10):\n",
    "        dataset.loc[i,('mnth')] = 'October'\n",
    "    elif(dataset.loc[i,('mnth')] == 11):\n",
    "        dataset.loc[i,('mnth')] = 'November'\n",
    "    elif(dataset.loc[i,('mnth')] == 12):\n",
    "        dataset.loc[i,('mnth')] = 'December'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holiday: weather day is holiday or not (extracted fromHoliday Schedule)\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('holiday')] == 1):\n",
    "        dataset.loc[i,('holiday')] = 'Yes'\n",
    "    elif(dataset.loc[i,('holiday')] == 0):\n",
    "        dataset.loc[i,('holiday')] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weekday: Day of the week\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('weekday')] == 1):\n",
    "        dataset.loc[i,('weekday')] = 'Monday'\n",
    "    elif(dataset.loc[i,('weekday')] == 2):\n",
    "        dataset.loc[i,('weekday')] = 'Tuesday'\n",
    "    elif(dataset.loc[i,('weekday')] == 3):\n",
    "        dataset.loc[i,('weekday')] = 'Wednesday'\n",
    "    elif(dataset.loc[i,('weekday')] == 4):\n",
    "        dataset.loc[i,('weekday')] = 'Thursday'\n",
    "    elif(dataset.loc[i,('weekday')] == 5):\n",
    "        dataset.loc[i,('weekday')] = 'Friday'\n",
    "    elif(dataset.loc[i,('weekday')] == 6):\n",
    "        dataset.loc[i,('weekday')] = 'Saturday'\n",
    "    elif(dataset.loc[i,('weekday')] == 0):\n",
    "        dataset.loc[i,('weekday')] = 'Sunday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workingday: If day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "for i in range(0,r):\n",
    "    if(dataset.loc[i,('workingday')] == 1):\n",
    "        dataset.loc[i,('workingday')] = 'Yes'\n",
    "    elif(dataset.loc[i,('workingday')] == 0):\n",
    "        dataset.loc[i,('workingday')] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp: Normalized temperature in Celsius. \n",
    "#The values are derived via (t-t_min)/(t_max-t_min),t_min=-8, t_max=+39 (only in hourly scale)\n",
    "t_min=-8\n",
    "t_max=+39\n",
    "ActualTemp = pd.DataFrame()   \n",
    "ActualTemp = (dataset['temp']*(t_max - t_min) ) + t_min\n",
    "dataset['ActualTemp'] = ActualTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atemp: Normalized feeling temperature in Celsius. \n",
    "#The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
    "t_min=-16\n",
    "t_max=+50\n",
    "ActualAtemp = pd.DataFrame()   \n",
    "ActualAtemp = (dataset['atemp']*(t_max - t_min) ) + t_min\n",
    "dataset['ActualAtemp'] = ActualAtemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hum: Normalized humidity. The values are divided to 100 (max)\n",
    "Actualhum = pd.DataFrame() \n",
    "Actualhum = dataset['hum'] * 100\n",
    "dataset['Actualhum'] = Actualhum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "Actualwindspeed = pd.DataFrame()\n",
    "Actualwindspeed= dataset['windspeed'] * 67\n",
    "dataset['Actualwindspeed']= Actualwindspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataCon is a dataframe containing all continuous variables from dataset \n",
    "#Here we are adding actual values for ActualTemp and ActualAtemp which we have calculated using given formula in problem statement\n",
    "#Since we will use actual values for these variable in feature analysis and outier analysis to get accurate results\n",
    "DataConActual = pd.DataFrame()\n",
    "DataConActual['ActualTemp'] = dataset['ActualTemp']\n",
    "DataConActual['ActualAtemp'] = dataset['ActualAtemp']\n",
    "DataConActual['Actualhum'] = dataset['Actualhum']\n",
    "DataConActual['Actualwindspeed'] = dataset['Actualwindspeed']\n",
    "DataConActual.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between Season and Count of bikes rented\n",
    "sns.factorplot(\"season\", \"cnt\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented for all seasons\")\n",
    "plt.xlabel(\"seasons\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between Year and Count of bikes rented\n",
    "sns.factorplot(\"yr\", \"cnt\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented per year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between Year and Count of bikes rented showing the growth in all seasons\n",
    "sns.factorplot(\"yr\", \"cnt\", \"season\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented per year in all seasons\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In yr 2012 the bike renting count has incresed \n",
    "#growth in Bike Renting\n",
    "growth = dataset['cnt'][dataset['yr'] == '2012' ].sum() - dataset['cnt'][dataset['yr'] == '2011' ].sum() \n",
    "growth_percentage = growth*100/dataset['cnt'][dataset['yr'] == '2011' ].sum()\n",
    "growth_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between month and Count of bikes rented\n",
    "sns.factorplot(\"cnt\", \"mnth\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented per month\")\n",
    "plt.xlabel(\"Count of Bikes Rented\")\n",
    "plt.ylabel(\"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between Holiday and Count of bikes rented\n",
    "sns.factorplot(\"holiday\", \"cnt\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented for holiday\")\n",
    "plt.xlabel(\"holiday\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between workingday and Count of bikes rented\n",
    "sns.factorplot(\"workingday\", \"cnt\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented for all workingday\")\n",
    "plt.xlabel(\"workingday\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between weekdays and Count of bikes rented\n",
    "sns.factorplot(\"cnt\", \"weekday\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented for weekdays\")\n",
    "plt.xlabel(\"Count of Bikes Rented\")\n",
    "plt.ylabel(\"weekday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bargraph between weather and Count of bikes rented\n",
    "sns.factorplot(\"weathersit\", \"cnt\", data=dataset_copy, kind=\"bar\", palette=\"muted\", legend=False)\n",
    "plt.title(\"Count of Bikes Rented for all weathers\")\n",
    "plt.xlabel(\"weathersit\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for Actual Temperature\n",
    "plt.scatter(DataConActual['ActualTemp'], dataset_copy['cnt'],color='gray')\n",
    "plt.title(\"Count of Bikes Rented for Actual Temperature\")\n",
    "plt.xlabel(\"Actual Temperature\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for Actual Feeling Temperature\n",
    "plt.scatter(DataConActual['ActualAtemp'], dataset_copy['cnt'],color='green')\n",
    "plt.title(\"Count of Bikes Rented for Actual Feeling Temperature\")\n",
    "plt.xlabel(\"Feeling Temperature(Actual Atemp)\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for Actual Humidity\n",
    "plt.scatter(DataConActual['Actualhum'], dataset_copy['cnt'])\n",
    "plt.title(\"Count of Bikes Rented according to Actual Humidity \")\n",
    "plt.xlabel(\"humidity\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for Actual Windspeed\n",
    "plt.scatter(DataConActual['Actualwindspeed'], dataset_copy['cnt'] , color='orange')\n",
    "plt.title(\"Count of Bikes Rented according to Actual windspeed\")\n",
    "plt.xlabel(\"Actual Windspeed\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Violinplot showing data of dependent variable 'cnt' \n",
    "#So average count of bikes rented  per day over the year is between 4000 to 5000\n",
    "sns.violinplot(x = \"cnt\", data=dataset_copy)\n",
    "plt.xlabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Rent Count by season in weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot showing count of bikes rented in weekdays in all seasons\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.boxplot(\"weekday\", \"cnt\", hue=\"season\", data=dataset_copy)\n",
    "plt.title('Count as per weekdays in all seasons')\n",
    "plt.xticks(rotation = 90);\n",
    "plt.xlabel(\"weekdays\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Rent Count by weather in weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot showing count of bikes rented in weekdays in all weathers\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.boxplot(\"weekday\", \"cnt\", hue=\"weathersit\", data=dataset_copy)\n",
    "plt.title('Count as per weekdays')\n",
    "plt.xticks(rotation = 90);\n",
    "plt.xlabel(\"weekdays\")\n",
    "plt.ylabel(\"Count of Bikes Rented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot for Actual continuous data\n",
    "for i in DataConActual.columns:\n",
    "    sns.boxplot(dataset[i])\n",
    "    plt.show()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms with Mean for skewed Data \n",
    "#area codes\n",
    "\n",
    "for i in DataConActual.columns:\n",
    "    x= dataset[i]\n",
    "    plt.hist(x,bins=20)\n",
    "    plt.axvline(x.mean(), color='Red', linewidth=2)\n",
    "    plt.ylabel('frequency')\n",
    "    plt.xlabel(i)\n",
    "    plt.show()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Density Plot and Histogram of all variables\n",
    "df = dataset\n",
    "for i in DataConActual:\n",
    "    sns.distplot( dataset[i] , hist = True, color = 'red' ,norm_hist = True, kde = True, fit=norm)\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values in dataset\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for invalid data  \n",
    "for i in DataCat:\n",
    "    if(i != 'instant' and i != 'dteday'):\n",
    "        print(i)\n",
    "        print(pd.unique(dataset_copy1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot to visualize Outliers \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "for i in DataConActual.columns :\n",
    "    print(i)\n",
    "    plt.boxplot(dataset[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Analysis\n",
    " \n",
    "cnames = DataConActual.columns\n",
    "for col in cnames:\n",
    "    percentile = dataset[col].quantile([0.25,0.75]).values\n",
    "    iqr = percentile[1] - percentile[0]\n",
    "    minimum = percentile[0] - (iqr*1.5)\n",
    "    maximum = percentile[1] + (iqr*1.5)\n",
    "    #print(col,percentile,maximum,minimum)\n",
    "    dataset[col][dataset[col] <= minimum] = minimum\n",
    "    dataset[col][dataset[col] >= maximum] = maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot to visualize after Outlier correction\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "for i in DataConActual.columns :\n",
    "    print(i)\n",
    "    plt.boxplot(dataset[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection for continuos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation plot for Continuous variables\n",
    "cnames = DataConActual.columns\n",
    "df_corr = DataConActual.loc[:,cnames]\n",
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "#Generate correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous Variables selection using corr()function\n",
    "DataCon_corr = DataConActual.corr()\n",
    "\n",
    "#from continuous variables variables\n",
    "DataCon_corrVar = DataCon_corr[DataCon_corr > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCon_corrVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a list DataConCorrVar,which contains values only greater than 0.8\n",
    "import numpy as np\n",
    "#DataCon_corrVar = DataCon_corrVar.replace(np.nan,-1)\n",
    "DataConCorrVar = []\n",
    "\n",
    "for i  in range(0,DataCon_corrVar.shape[1]): \n",
    "        for j  in range(0,DataCon_corrVar.shape[1]):\n",
    "            if(i != j):\n",
    "                if((DataCon_corrVar.iloc[i,j] > 0.8).any(axis=0)):\n",
    "#print(DataCon_corrVar.columns[i]+ \" , \"+DataCon_corrVar.columns[j] + \" :\",DataCon_corrVar.iloc[i,j])\n",
    "                    DataConCorrVar.append((DataCon_corrVar.columns[i] , DataCon_corrVar.columns[j] ,DataCon_corrVar.iloc[i,j] ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to DataFrame\n",
    "DataConCorrVar = pd.DataFrame(DataConCorrVar)\n",
    "DataConCorrVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['atemp'],axis=1)\n",
    "DataCon = DataCon.drop(['atemp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list corrVar which will contain variable names and their p-values from chi2_contigency test\n",
    "corrVar = []\n",
    "for i in DataCat.columns:\n",
    "    for j in DataCat.columns:\n",
    "        if(i!=j):\n",
    "            #print(i,j)\n",
    "            chi,p,def1,ex = chi2_contingency(pd.crosstab(DataCat[i],DataCat[j]))\n",
    "            #print(p)\n",
    "            corrVar.append((i,j,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to DataFrame\n",
    "corrVar = pd.DataFrame(corrVar)\n",
    "#corrVar[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If p-value < 0.05: significant result, reject null hypothesis (H0), dependent.\n",
    "#If independent variables are dependent to each other we can drop one of them .\n",
    "#If p-value > 0.05: not significant result, fail to reject null hypothesis (H0), independent.\n",
    "\n",
    "corrVar[corrVar[2] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping categorical variables'mnth','holiday' as per chi square test result\n",
    "#dropping 'instant','dteday' , Since they are not carrying important environmental and seasonal information to the model as per problem statement\n",
    "dataset = dataset.drop(['instant','dteday','mnth','weekday','weathersit'],axis=1)\n",
    "DataCat =DataCat.drop(['instant','dteday','mnth','weekday','weathersit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DataSet \n",
    "DataSet = pd.DataFrame()\n",
    "DependentVariables = pd.DataFrame()\n",
    "DataSet = dataset.copy()\n",
    "\n",
    "#Droping dependent variables and variables which we have created for correlation test\n",
    "DependentVariables =  dataset[['casual', 'registered', 'cnt']]\n",
    "DataSet = DataSet.drop(['ActualTemp', 'ActualAtemp', 'Actualhum','Actualwindspeed','casual', 'registered', 'cnt'],axis=1)\n",
    "DataCon = DataCon.drop([ 'casual', 'registered', 'cnt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final DataSet for model development\n",
    "DataSet.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we already have continuous data given in normalised form .\n",
    "#We are passing the same data to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Histogram for Normality check\n",
    "cnames = DataCon.columns\n",
    "for i in cnames:\n",
    "    plt.hist(dataset[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create linear data. Save target variable first and #Add continous variables\n",
    "dataset_LR = pd.DataFrame()\n",
    "dataset_LR = DataCon.copy()\n",
    "\n",
    "\n",
    "#Creating dummy Variables for categorical variables\n",
    "cat_names = DataCat.columns\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(DataSet[i], prefix = i)\n",
    "    \n",
    "    dataset_LR = dataset_LR.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_LR.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model for Target Variable : Casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Assigned independent features to X and assigned dependent feature to y.Here we\n",
    "#Are building regression model for ‘casual’ prediction .So taking ‘casual’ as y\n",
    "\n",
    "y = DependentVariables['casual']\n",
    "X = dataset_LR[dataset_LR.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel = sm.OLS(y_train,X_train)\n",
    "LRdataModel = LRdataModel.fit()\n",
    "LRpredictions_casual = LRdataModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#Error Measure Rate\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Summary of Actual data\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#Summary of Predicted data\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#As from summary we can see negative values in predictions \n",
    "#Replacing negative values with 1 , Since count can't be negative for bikes rented\n",
    "LRpredictions_casual[LRpredictions_casual < 0]\n",
    "LRpredictions_casual[LRpredictions_casual<0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary of Predicted data after replacing negative values\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9\n",
    "#RMSE After removal of negative Values\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 11\n",
    "#Summary Statistics matrix from LRdataModel \n",
    "LRdataModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#As in last model we have seen that p-values for 'season_fall','yr_2011','holiday_Yes' are more than 0.05\n",
    "#If p-value is greater than 0.05 , So we can accept that the null hypothesis saying that this variable is \n",
    "#not contributing much information to model and we can drop them to reduce the effect of multicollinearity.\n",
    "\n",
    "X = X.drop(['season_fall','yr_2011','holiday_Yes'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel = sm.OLS(y_train,X_train)\n",
    "LRdataModel = LRdataModel.fit()\n",
    "LRpredictions_casual = LRdataModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Summary of Actual data\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#Summary of Predicted data\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#As from summary we can see negative values in predictions \n",
    "#Replacing negative values with 1 , Since count can't be negative for bikes rented\n",
    "LRpredictions_casual[LRpredictions_casual < 0]\n",
    "LRpredictions_casual[LRpredictions_casual<0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary of Predicted data after replacing negative values\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9\n",
    "#RMSE After removal of negative Values\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 11\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#As in last model we have seen that p-values for 'season_springer','season_winter','workingday_Yes' are more than 0.05\n",
    "#If p-value is greater than 0.05 , So we can accept that the null hypothesis saying that this variable is \n",
    "#not contributing much information to model and we can drop them to reduce the effect of multicollinearity.\n",
    "\n",
    "X = X.drop(['season_springer','season_winter','workingday_Yes'],axis=1)\n",
    "X_casual = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel = sm.OLS(y_train,X_train)\n",
    "LRdataModel = LRdataModel.fit()\n",
    "LRpredictions_casual = LRdataModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Summary of Actual data\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#Summary of Predicted data\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#As from summary we can see negative values in predictions \n",
    "#Replacing negative values with 1 , Since count can't be negative for bikes rented\n",
    "LRpredictions_casual[LRpredictions_casual < 0]\n",
    "LRpredictions_casual[LRpredictions_casual<0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary of Predicted data after replacing negative values\n",
    "LRpredictions_casual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9\n",
    "#RMSE After removal of negative Values\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 11\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model for Target Variable : Casual [Log]\n",
    " [Since we got negative predicted values, we will do log transformation and run regression model again]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Taking log on y for passing it to regression model\n",
    "logY = []\n",
    "for i in range(0,y.shape[0]):\n",
    "    logY.append(math.log10(y[i]))\n",
    "logY = pd.DataFrame(logY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,logY,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel_log = sm.OLS(y_train,X_train)\n",
    "LRdataModel_log = LRdataModel_log.fit()\n",
    "LRpredictions_casual_log = LRdataModel_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "# As the predicted values are in log format, use exponential(exp) to convert from log to non-log values\n",
    "LRpredictions_NonLog = []\n",
    "for i in range(0,LRpredictions_casual_log.shape[0]):\n",
    "    LRpredictions_NonLog.append(math.exp(LRpredictions_casual_log.iloc[i]))\n",
    "LRpredictions_NonLog = pd.DataFrame(LRpredictions_NonLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "# As the target variable passed is in log format, use exponential(exp) to convert from log to non-log values\n",
    "y_test_NonLog = []\n",
    "for i in range(0,y_test.shape[0]):\n",
    "    y_test_NonLog.append(math.exp(y_test.iloc[i,0]))\n",
    "y_test_NonLog =pd.DataFrame(y_test_NonLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_NonLog,y_test_NonLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#Summary y_test_NonLog\n",
    "y_test_NonLog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary LRpredictions_NonLog\n",
    "LRpredictions_NonLog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output For Casual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions(LRpredictions_casual_log) to get float number\n",
    "LRpredictions_casual_Final = pd.DataFrame(LRpredictions_casual_log)\n",
    "for i in range(0,LRpredictions_casual_log.shape[0]):\n",
    "    LRpredictions_casual_Final.iloc[i] = math.pow(10,LRpredictions_casual_log.iloc[i])\n",
    "    \n",
    "LRpredictions_casual_Final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model for Target Variable :  Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Split dataset\n",
    "#Applying Model for 2nd dependent variable 'registered' \n",
    "y = DependentVariables['registered']\n",
    "X = dataset_LR[dataset_LR.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "LRdataModel = sm.OLS(y_train,X_train)\n",
    "LRdataModel = LRdataModel.fit()\n",
    "LRpredictions_registered = LRdataModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#Summary of Actual data\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Summary of Predicted data\n",
    "LRpredictions_registered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_registered))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_registered,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "X=X.drop(['yr_2011'],axis=1)\n",
    "X_registered = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "LRdataModel = sm.OLS(y_train,X_train)\n",
    "LRdataModel = LRdataModel.fit()\n",
    "LRpredictions_registered = LRdataModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#Summary of Actual data\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Summary of Predicted data\n",
    "LRpredictions_registered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test, LRpredictions_registered))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_registered,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model for Target Variable : Registered [Log]\n",
    " [For better results, will do log transformation and run regression model again]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Taking log on y and passing it to regression model\n",
    "logY = []\n",
    "for i in range(0,y.shape[0]):\n",
    "    logY.append(math.log10(y[i]))\n",
    "logY = pd.DataFrame(logY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,logY,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel_log = sm.OLS(y_train,X_train)\n",
    "LRdataModel_log = LRdataModel_log.fit()\n",
    "LRpredictions_registered_log = LRdataModel_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "# As the predicted values are in log format, use exponential(exp) to convert from log to non-log values\n",
    "LRpredictions_NonLog = []\n",
    "for i in range(0,LRpredictions_registered_log.shape[0]):\n",
    "    LRpredictions_NonLog.append(math.exp(LRpredictions_registered_log.iloc[i]))\n",
    "LRpredictions_NonLog = pd.DataFrame(LRpredictions_NonLog)\n",
    "\n",
    "\n",
    "#Step 5\n",
    "# As the predicted values are in log format, use exponential(exp) to convert from log to non-log values\n",
    "y_test_NonLog = []\n",
    "for i in range(0,y_test.shape[0]):\n",
    "    y_test_NonLog.append(math.exp(y_test.iloc[i,0]))\n",
    "y_test_NonLog =pd.DataFrame(y_test_NonLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(LRpredictions_NonLog,y_test_NonLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#Summary y_test_NonLog\n",
    "y_test_NonLog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8\n",
    "#Summary LRpredictions_NonLog\n",
    "LRpredictions_NonLog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9\n",
    "#Summary Statistics matrix from log LR Model \n",
    "LRdataModel_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output For Registered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions(LRpredictions_casual_log) to get float number\n",
    "LRpredictions_registered_Final = pd.DataFrame(LRpredictions_registered_log)\n",
    "for i in range(0,LRpredictions_registered_log.shape[0]):\n",
    "    LRpredictions_registered_Final.iloc[i] = math.pow(10,LRpredictions_registered_log.iloc[i])\n",
    "    \n",
    "LRpredictions_registered_Final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output for Testdata For 'cnt' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per problem statement given cnt = casual + Registered\n",
    "#cnt: count of total rental bikes including both casual and registered\n",
    "#We are calculating predicted cnt with the sum of predicted values of registered and casual variables.\n",
    "\n",
    "#Final Count\n",
    "Count_Prediction = LRpredictions_registered_Final + LRpredictions_casual_Final\n",
    "Count_Prediction = round(Count_Prediction)\n",
    "Count_Prediction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Prediction.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical  variables to codes, So that we can easily compute and impute easily\n",
    "for i in range(0,DataSet.shape[1]):\n",
    "    if(DataSet.iloc[:,i].dtypes == 'object'):\n",
    "        DataSet.iloc[:,i] = pd.Categorical(DataSet.iloc[:,i])\n",
    "        DataSet.iloc[:,i] = DataSet.iloc[:,i].cat.codes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree for Casual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['casual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "#Applying Model\n",
    "DataModel = DecisionTreeRegressor(random_state =6,max_depth=2)\n",
    "DataModel = DataModel.fit(X_train,y_train)\n",
    "DT_predictions_casual = DataModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#Create dot file to visualise tree  #http://webgraphviz.com/\n",
    "df = tree.export_graphviz(DataModel, out_file='tree_casual.dot' ,feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "#Mean Absolute Error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,DT_predictions_casual)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,DT_predictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(DT_predictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree for registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['registered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model\n",
    "DataModel = DecisionTreeRegressor(random_state =6,max_depth=2)\n",
    "DataModel = DataModel.fit(X_train,y_train)\n",
    "DT_predictions = DataModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dot file to visualise tree  #http://webgraphviz.com/\n",
    "df = tree.export_graphviz(DataModel, out_file='tree_registered.dot' ,feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,DT_predictions)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,DT_predictions))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(DT_predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['casual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Model\n",
    "DataModel_RF = RandomForestRegressor(random_state=7, max_depth=3, n_estimators=125)\n",
    "DataModel_RF = DataModel_RF.fit(X_train,y_train)\n",
    "RF_Predictions_casual = DataModel_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,RF_Predictions_casual)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,RF_Predictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(RF_Predictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['registered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Model\n",
    "DataModel_RF = RandomForestRegressor(random_state=7, max_depth=3, n_estimators=125)\n",
    "DataModel_RF = DataModel_RF.fit(X_train,y_train)\n",
    "RF_Predictions_registered = DataModel_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,RF_Predictions_registered)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,RF_Predictions_registered))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(RF_Predictions_registered,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['casual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 KNN implementation\n",
    "KNN_Model = KNeighborsRegressor()\n",
    "KNN_Model = KNN_Model.fit(X_train,y_train)\n",
    "KNNpredictions_casual = KNN_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,KNNpredictions_casual)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,KNNpredictions_casual))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(KNNpredictions_casual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "X = DataSet[DataSet.columns]\n",
    "y = DependentVariables['registered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 KNN implementation\n",
    "KNN_Model = KNeighborsRegressor()\n",
    "KNN_Model = KNN_Model.fit(X_train,y_train)\n",
    "KNNpredictions_registered = KNN_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "MeanAbsoluteError = mean_absolute_error(y_test,KNNpredictions_registered)\n",
    "MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "rms = math.sqrt(mean_squared_error(y_test,KNNpredictions_registered))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMLSE Error (root mean square log error value)\n",
    "def rmsle(ypred, ytest) : \n",
    "    assert len(ytest) == len(ypred)\n",
    "    return np.sqrt(np.mean((np.log1p(ypred) - np.log1p(ytest))**2))\n",
    "\n",
    "\n",
    "rmsle(KNNpredictions_registered,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are freezing Linear Regression model \n",
    "#As we have observed ERROR MESEARE rates for Linear Regression model are low as compared to other Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model for casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For casual\n",
    "#Assigning data to X and y\n",
    "y = DependentVariables['casual']\n",
    "X = X_casual\n",
    "\n",
    "#Taking log on y and passing it to regression model\n",
    "logY = []\n",
    "for i in range(0,y.shape[0]):\n",
    "    logY.append(math.log10(y[i]))\n",
    "logY = pd.DataFrame(logY)\n",
    "\n",
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,logY,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel_log = sm.OLS(y_train,X_train)\n",
    "LRdataModel_log = LRdataModel_log.fit()\n",
    "LRpredictions_casual_log = LRdataModel_log.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions(LRpredictions_casual_log) to get float number\n",
    "LRpredictions_casual_Final = pd.DataFrame(LRpredictions_casual_log)\n",
    "for i in range(0,LRpredictions_casual_log.shape[0]):\n",
    "    LRpredictions_casual_Final.iloc[i] = math.pow(10,LRpredictions_casual_log.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRpredictions_casual_Final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model for registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning data to X and y\n",
    "y = DependentVariables['registered']\n",
    "X = X_registered\n",
    "\n",
    "#Taking log on y and passing it to regression model\n",
    "logY = []\n",
    "for i in range(0,y.shape[0]):\n",
    "    logY.append(math.log10(y[i]))\n",
    "logY = pd.DataFrame(logY)\n",
    "\n",
    "#Sampling \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,logY,test_size=0.2,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "import math\n",
    "LRdataModel_log = sm.OLS(y_train,X_train)\n",
    "LRdataModel_log = LRdataModel_log.fit()\n",
    "LRpredictions_registered_log = LRdataModel_log.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions(LRpredictions_registered_log) to get float number\n",
    "LRpredictions_registered_Final = pd.DataFrame(LRpredictions_registered_log)\n",
    "for i in range(0,LRpredictions_registered_log.shape[0]):\n",
    "    LRpredictions_registered_Final.iloc[i] = math.pow(10,LRpredictions_registered_log.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRpredictions_registered_Final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predicted Count for dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per problem statement given cnt = casual + Registered\n",
    "#cnt: count of total rental bikes including both casual and registered\n",
    "#We are calculating predicted cnt with the sum of predicted values of registered and casual variables.\n",
    "\n",
    "#Final Count\n",
    "Count_Prediction = round(LRpredictions_registered_Final) + round(LRpredictions_casual_Final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating output file for dataset\n",
    "DataTestFinal= pd.read_csv(\"Day.csv\")\n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "df_output[DataTestFinal.columns] = DataTestFinal[DataTestFinal.columns]\n",
    "df_output['predicted_casual'] = round(LRpredictions_casual_Final)\n",
    "df_output['predicted_registered'] = round(LRpredictions_registered_Final)\n",
    "df_output['Predicted_Count'] = Count_Prediction\n",
    "df_output.to_csv('Bike_Renting_Python_Output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
